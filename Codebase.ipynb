{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28b1becd",
   "metadata": {},
   "source": [
    "# STOR515 Final Project Codebase\n",
    "### Modeling Inventory Decisions for Stoney River Steakhouse\n",
    "\n",
    "#### Project Authors: Alex Huml, Carter Hall, Thomas Bridges, Ian Wilson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf25198",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 15\n",
    "import numpy as np \n",
    "import statistics as stats # stats.NormalDist is the norm. dist. function w/ object 'cdf'\n",
    "import pandas as pd # Pretty-printing, exporting dataframes to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a000c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeLoveSteak:\n",
    "    \"\"\"Modeling the demand for Strip Loins as a finite-horizon Markov Decision Process.\"\"\"\n",
    "    def __init__(self, M, N, mu, sigma, sellPrice, priceyint, steakName):\n",
    "        \"\"\"Initialization Function.\n",
    "        \n",
    "        Parameters:\n",
    "        M := Limit on storage capacity.\n",
    "        N := Number of decision epochs.\n",
    "        \"\"\"\n",
    "        self.M = M\n",
    "        self.N = N\n",
    "        self.S = set(range(self.M+1))\n",
    "        self.T = set(range(1,self.N+1))\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.sp = sellPrice\n",
    "        self.priceyint = priceyint\n",
    "        self.ustar, self.astar = self.optimality(steakName)\n",
    "        self.storeResults(steakName)\n",
    "        \n",
    "    def A(self, s):\n",
    "        '''Function representing action space.\n",
    "        \n",
    "        Parameters:\n",
    "        s := State from state space S.\n",
    "        '''\n",
    "        return set(range(0,self.M - s + 1))\n",
    "        \n",
    "    def f(self, s):\n",
    "        \"\"\"Revenue generated from selling strip loins at $44/pound.\n",
    "        \n",
    "        Parameters:\n",
    "        s := State indicating number of loins sold.\n",
    "        \"\"\"\n",
    "        return self.sp * s\n",
    "    \n",
    "    def price(self, t):\n",
    "        \"\"\"Price for Strip Loin, adjusted for inflation via CPI metric.\n",
    "        \n",
    "        Parameters:\n",
    "        t := Epoch in T\n",
    "        \"\"\"\n",
    "        return self.priceyint * (1 + (0.0125 / (np.sqrt(t) - 0.5)))\n",
    "    \n",
    "    def CDF(self, s):\n",
    "        \"\"\"Function for discretized probability that uses the normal CDF.\n",
    "        \n",
    "        Parameters:\n",
    "        s := State in S\n",
    "        \"\"\"\n",
    "        return stats.NormalDist(self.mu, self.sigma).cdf(s)\n",
    "    \n",
    "    def pt(self, j, s, a):\n",
    "        '''Transition probability function.\n",
    "            \n",
    "        Parameters:\n",
    "        j,s := states in S\n",
    "        a := action in A\n",
    "        \n",
    "        Returns:\n",
    "        0 if j > s + a\n",
    "        CDF(s + a - j) - CDF(s + a - j - 1) if 0 < j <= s + a\n",
    "        1 - CDF(s + a) otherwise\n",
    "        '''\n",
    "        assert type(j) == type(s) == type(a) == type(3)\n",
    "        \n",
    "        return 0 if j > s + a else ((self.CDF(s + a - j) - self.CDF(s + a - j - 1)) if ((0 < j) and (j <= s + a)) \n",
    "                 else (1 - self.CDF(s + a)))\n",
    "    \n",
    "    def rt(self, t, s, a = 0):\n",
    "        \n",
    "        if t == self.N:\n",
    "            return 0\n",
    "        \n",
    "        return -a*self.price(t) + sum([self.CDF(k) - self.CDF(k - 1) * self.f(k) for k in range(s+a+1)]) + sum([self.CDF(s+a) * self.f(s+a) for k in range(s+a+1, self.M+1)])\n",
    "    \n",
    "    def optimalAction(self, d):\n",
    "        '''Function to determine which action corresponds to optimal policy.\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            d: dict -> dictionary of (action, optimality eqn. value) \n",
    "        '''\n",
    "        v = max(d.values())\n",
    "        for k in d.keys():\n",
    "            if d[k] == v:\n",
    "                return k\n",
    "\n",
    "        raise ValueError(\"Should never get here, but.\")\n",
    "    \n",
    "    def optimality(self, steakName):\n",
    "        '''Implements algorithm to find optimal policy via backward induction.'''\n",
    "        t = len(self.T) # From 1 to N + 1, this returns N \n",
    "        ustar = np.zeros([len(self.S), t])\n",
    "        astar = np.zeros([len(self.S), t])\n",
    "        \n",
    "        # BC computation -- u_{N+1}^{*} (s) = r_{N} s for all s in S\n",
    "        for s in self.S:\n",
    "            ustar[s,-1] = self.rt(t,s)\n",
    "        \n",
    "        while t != 1:\n",
    "            print(steakName + \": \" + str(t))\n",
    "            t -= 1\n",
    "            for s in self.S:\n",
    "                l = dict()\n",
    "                for a in self.A(s):\n",
    "                    temp = self.rt(t,s,a) + sum([self.pt(j,s,a) * ustar[j,t] for j in self.S])\n",
    "                    l[a] = l.get(a, 0) + temp\n",
    "                ustar[s,t-1] = round(max(l.values()), 4) # Rounding this because of PDF output -- doesn't change answer\n",
    "                astar[s,t-1]= self.optimalAction(l)\n",
    "        \n",
    "        ustar = self.getOptimalityTable(ustar)\n",
    "        astar = self.getOptimalPolicy(astar)\n",
    "        return ustar, astar\n",
    "\n",
    "    def getOptimalPolicy(self, astar):\n",
    "        '''Pretty-prints the optimal policy dataframe.'''\n",
    "        return pd.DataFrame(astar, columns = ['Week {}'.format(t) for t in range(1,self.N+1)], \n",
    "                                   index   = ['State {}'.format(s) for s in range(0,len(self.S))])\n",
    "    \n",
    "    def getOptimalityTable(self, ustar):\n",
    "        '''Pretty-prints the total expected reward dataframe.'''\n",
    "        return pd.DataFrame(ustar, columns = ['Week {}'.format(t) for t in range(1,self.N+1)], \n",
    "                                   index   = ['State {}'.format(s) for s in range(0,len(self.S))])\n",
    "    \n",
    "    \n",
    "    def storeResults(self, steakName):\n",
    "        with pd.ExcelWriter(\"./MDPResults\" + steakName + \".xlsx\") as writer:\n",
    "            self.astar.to_excel(writer, sheet_name=\"ExpReward\", index=True)\n",
    "            self.ustar.to_excel(writer, sheet_name=\"OptPolicy\", index=True)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb9c96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "striploin = WeLoveSteak(168, 32, 112, 43, 44, 8.96, \"striploin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5320a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cowboy = WeLoveSteak(171, 32, 54, 26, 36, 11.32, \"cowboy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3ea58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ribeye = WeLoveSteak(360, 32, 119, 54, 48, 12.68, \"ribeye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fb25a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tenderloin = WeLoveSteak(588, 32, 188, 89, 75, 14.98, \"tenderloin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea974a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
