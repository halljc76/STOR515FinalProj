{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 15\n",
    "import numpy as np \n",
    "import statistics as stats # stats.NormalDist is the norm. dist. function w/ object 'cdf'\n",
    "import pandas as pd # Pretty-printing, exporting dataframes to Excel\n",
    "\n",
    "import threading\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeLoveSteak:\n",
    "    \"\"\"Modeling the demand for delicious steaks as a finite-horizon Markov Decision Process.\"\"\"\n",
    "    def __init__(self, M, N, mu, sigma, sellPrice, priceyint, steakName):\n",
    "        \"\"\"Initialization Function.\n",
    "        \n",
    "        Parameters:\n",
    "        M := Limit on storage capacity.\n",
    "        N := Number of decision epochs.\n",
    "        S := Set of States, T := Set of Epochs\n",
    "        mu, sigma: Normal Dist. params\n",
    "        sp := Selling price \n",
    "        priceyint := Avg 2021 price\n",
    "        steakName := Name of steak\n",
    "        \"\"\"\n",
    "        self.M = M\n",
    "        self.N = N\n",
    "        self.S = set(range(self.M+1))\n",
    "        self.T = set(range(1,self.N+1))\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.sp = sellPrice\n",
    "        self.priceyint = priceyint\n",
    "        self.ustar, self.astar = self.optimality(steakName)\n",
    "        self.storeResults(steakName)\n",
    "        \n",
    "    def A(self, s):\n",
    "        '''Function representing action space.\n",
    "        \n",
    "        Parameters:\n",
    "        s := State from state space S.\n",
    "        '''\n",
    "        return set(range(0,self.M - s + 1))\n",
    "    def f(self, s):\n",
    "        \"\"\"Revenue generated from selling strip loins at $44/pound.\n",
    "        \n",
    "        Parameters:\n",
    "        s := State indicating number of loins sold.\n",
    "        \"\"\"\n",
    "        return self.sp * s\n",
    "    \n",
    "    def price(self, t):\n",
    "        \"\"\"Price for Strip Loin, adjusted for inflation via inflation rate.\n",
    "        \n",
    "        Parameters:\n",
    "        t := Epoch in T\n",
    "        \"\"\"\n",
    "        return self.priceyint * (1 + (0.05 / (np.sqrt(t) - 0.5)))\n",
    "    \n",
    "    def CDF(self, s):\n",
    "        \"\"\"Function for discretized probability that uses the normal CDF.\n",
    "        \n",
    "        Parameters:\n",
    "        s := State in S\n",
    "        \"\"\"\n",
    "        return stats.NormalDist(self.mu, self.sigma).cdf(s)\n",
    "    \n",
    "    def pt(self, j, s, a):\n",
    "        '''Transition probability function.\n",
    "            \n",
    "        Parameters:\n",
    "        j,s := states in S\n",
    "        a := action in A\n",
    "        \n",
    "        Returns:\n",
    "        0 if j > s + a\n",
    "        CDF(s + a - j) - CDF(s + a - j - 1) if 0 < j <= s + a\n",
    "        1 - CDF(s + a) otherwise\n",
    "        '''\n",
    "        assert type(j) == type(s) == type(a) == type(3)\n",
    "        \n",
    "        if j > s + a:\n",
    "            return 0\n",
    "        elif 0 < j and j <= s + a:\n",
    "            return (self.CDF(s + a - j) - self.CDF(s + a - j - 1))\n",
    "        return (1 - self.CDF(s + a))\n",
    "    \n",
    "    def rt(self, t, s, a = 0):\n",
    "        \"\"\"Reward function for finite-horizon MDP setup.\n",
    "        \n",
    "        Parameters:\n",
    "        t := Epoch in T\n",
    "        s := State in S\n",
    "        a := Action in A\n",
    "        \"\"\"\n",
    "        if t == self.N:\n",
    "            return 0\n",
    "        elif s+a == 0:\n",
    "            return 0\n",
    "        elif s+a == 1:\n",
    "            return (1-self.CDF(1))*self.f(1)\n",
    "        er = 0\n",
    "        er += (1-self.CDF(s+a))*self.f(s+a)\n",
    "        for i in range(s+a-1):\n",
    "            er += (self.f(i) * (self.CDF(i)-self.CDF(i-1)))\n",
    "        return er - self.price(t)*a\n",
    "            \n",
    "    def optimalAction(self, d):\n",
    "        '''Function to determine which action corresponds to optimal policy.\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            d: dict -> dictionary of (action, optimality eqn. value) \n",
    "        '''\n",
    "        v = max(d.values())\n",
    "        for k in d.keys():\n",
    "            if d[k] == v:\n",
    "                return k\n",
    "\n",
    "        raise ValueError(\"Should never get here, but.\")\n",
    "    \n",
    "    def optimality(self, steakName):\n",
    "        '''Implements algorithm to find optimal policy via backward induction.'''\n",
    "        t = len(self.T) # From 1 to N + 1, this returns N \n",
    "        ustar = np.zeros([len(self.S), t])\n",
    "        astar = np.zeros([len(self.S), t])\n",
    "        \n",
    "        # BC computation -- u_{N+1}^{*} (s) = r_{N} s for all s in S\n",
    "        for s in self.S:\n",
    "            ustar[s,-1] = self.rt(t,s)\n",
    "        \n",
    "        while t != 1:\n",
    "            print(steakName + \": \" + str(t))\n",
    "            t -= 1\n",
    "            for s in self.S:\n",
    "                l = dict()\n",
    "                for a in self.A(s):\n",
    "                    temp = self.rt(t,s,a) + sum([self.pt(j,s,a) * ustar[j,t] for j in self.S])\n",
    "                    l[a] = l.get(a, 0) + temp\n",
    "                ustar[s,t-1] = round(max(l.values()), 4) # Rounding this because of PDF output -- doesn't change answer\n",
    "                astar[s,t-1]= self.optimalAction(l)\n",
    "        \n",
    "        ustar = self.getOptimalityTable(ustar)\n",
    "        astar = self.getOptimalPolicy(astar)\n",
    "        return ustar, astar\n",
    "    def getOptimalPolicy(self, astar):\n",
    "        '''Pretty-prints the optimal policy dataframe.'''\n",
    "        return pd.DataFrame(astar, columns = ['Week {}'.format(t) for t in range(1,self.N+1)], \n",
    "                                   index   = ['State {}'.format(s) for s in range(0,len(self.S))])\n",
    "    \n",
    "    def getOptimalityTable(self, ustar):\n",
    "        '''Pretty-prints the total expected reward dataframe.'''\n",
    "        return pd.DataFrame(ustar, columns = ['Week {}'.format(t) for t in range(1,self.N+1)], \n",
    "                                   index   = ['State {}'.format(s) for s in range(0,len(self.S))])\n",
    "    \n",
    "    \n",
    "    def storeResults(self, steakName):\n",
    "        with pd.ExcelWriter(\"./MDPResults\" + steakName + \".xlsx\") as writer:\n",
    "            self.astar.to_excel(writer, sheet_name=\"OptPolicy\", index=True)\n",
    "            self.ustar.to_excel(writer, sheet_name=\"ExpReward\", index=True)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brute-Force (Takes... A Very Long Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WeLoveSteak(168, 32, 112, 43, 44, 8.96, \"striploin\")\n",
    "WeLoveSteak(171, 32, 54, 26, 36, 11.32, \"cowboy\")\n",
    "WeLoveSteak(360, 32, 119, 54, 48, 12.68, \"ribeye\")\n",
    "WeLoveSteak(588, 32, 188, 89, 75, 14.98, \"tenderloin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concurrent Programming Solution (Takes Slightly Less Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "def a():\n",
    "    return WeLoveSteak(168, 32, 112, 43, 44, 8.96, \"striploin\")\n",
    "    \n",
    "def b():\n",
    "    return WeLoveSteak(171, 32, 54, 26, 36, 11.32, \"cowboy\")\n",
    "\n",
    "def c():\n",
    "    return WeLoveSteak(360, 32, 119, 54, 48, 12.68, \"ribeye\")\n",
    "\n",
    "def d():\n",
    "    return WeLoveSteak(588, 32, 188, 89, 75, 14.98, \"tenderloin\")\n",
    "    \n",
    "thread1 = threading.Thread(target = a)\n",
    "thread2 = threading.Thread(target = b)\n",
    "thread3 = threading.Thread(target = c)\n",
    "thread4 = threading.Thread(target = d)\n",
    "\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "thread3.start()\n",
    "thread4.start()\n",
    "\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "thread3.join()\n",
    "thread4.join()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Time taken: {}\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
